---
title:  "[Hands-On ML] 2장. 머신러닝 프로젝트 처음부터 끝까지 - 3"
excerpt: "모델 훈련, 평가하고 배포하기"

categories:
  - Data Science & ML
tags:
  - [머신러닝, 파이썬, 데이터 시각화]

use_math: true
toc: true
toc_sticky: true

date: 2024-10-15
last_modified_at: 2024-10-15

header:
  overlay_image: https://cdn.jsdelivr.net/gh/Hyun3246/hyun3246.github.io@master/image/overlay image/Hands-on ML.png
---
## 모델 훈련하고 평가하기
Test set을 이용해서 모델을 훈련하고 평가할 수 있다. 본 예시에서는 `LinearRegression`, `DecisionTreeRegressor`, `RandomForestRegressor`의 3개 모델을 사용하였다.

또한, k-폴드 교차 검증을 사용해서 교차 검증을 진행하였다. 이는 10개의 서브셋을 만들어서 10번의 훈련을 진행하는데, 9개의 서브셋으로는 훈련을, 나머지 1개의 서브셋으로는 평가를 한다.

<br/>

## 하이퍼파라미터 튜닝
하이퍼파라미터를 조정하는 방법에는 그리드 서치와 랜덤 서치가 있다.

<span style="color:#F5F5F7">그리드 서치</span>는 시도해볼 값을 지정해서 수동으로 조합을 평가해보는 것이다. 예를 들어 하이퍼파라미터 A에 대해 3개의 값을 시도해보고 싶고, B에 대해서는 2개를 시도하고 싶다면, $3 \times 2 = 6$ 개의 조합을 시도해서 평가하게 된다.

반면 <span style="color:#F5F5F7">랜덤 서치</span>는 말 그대로 하이퍼파라미터를 랜덤하게 대입해서 평가하게 된다. 시도 횟수만 지정해주면 된다.

꼭 무엇이 더 좋다고 말할 수는 없다. 랜덤 서칙가 많은 조합을 시도하기는 하지만 그만큼 시간이 오래 걸린다. 별로 중요하지 않은 하이퍼파라미터였다면 시간이 아까울 수 있는 것이다.

<br/>

## 모델 저장, 불러오기
모델을 저장할 때는 `joblib` 라이브러리를 이용해서 저장한다. 불러올 때도 마찬가지.

<br/>

## 모델 론칭, 모니터링, 시스템 보수
모델을 론칭한 후에는 성능이 떨어지는지를 체크햐야 한다. 성능이 떨어졌을 때 알림을 보낼 수 있는 코드를 작성하는 것도 한 가지 방법이 될 수 있다.

<br/>

[코드 보러가기](https://github.com/Hyun3246/Code-Warehouse/blob/c90fb765d5a8ec70acb2c05a69ff52242414e636/Hands-On%20ML/Chapter%202/Predict_California_Housing_Price.ipynb)


<br/>
<br/>

*별도의 출처 표시가 있는 이미지를 제외한 모든 이미지는 강의자료에서 발췌하였음을 밝힙니다.*