{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Char-RNN"
      ],
      "metadata": {
        "id": "4sBdhWrgBEI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Train Set"
      ],
      "metadata": {
        "id": "n723cxlGDIMT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_DkA3in_V2G",
        "outputId": "b9b46f60-8cf9-42f8-c043-cc8ba01f436b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "shakespeare_url = 'https://homl.info/shakespeare'\n",
        "filepath = tf.keras.utils.get_file('shakespeare.txt', shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(shakespeare_text[:80])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtjQk96bBZtM",
        "outputId": "d9fbc2d0-2988-44d6-ab13-a765dd097c0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vec_layer = tf.keras.layers.TextVectorization(split='character', standardize='lower')\n",
        "text_vec_layer.adapt([shakespeare_text])\n",
        "encoded = text_vec_layer([shakespeare_text])[0]"
      ],
      "metadata": {
        "id": "7g9V6QXGBcL1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded -= 2\n",
        "n_tokens = text_vec_layer.vocabulary_size()-2\n",
        "dataset_size = len(encoded)"
      ],
      "metadata": {
        "id": "RXkrifEMBtzU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataset(sequence, length, shuffle=False, seed=None, batch_size=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length+1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=100_000, seed=seed)\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"
      ],
      "metadata": {
        "id": "sKNebqMcB8Zo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = 100\n",
        "tf.random.set_seed(42)\n",
        "train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True, seed=42)\n",
        "valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n",
        "test_set = to_dataset(encoded[1_060_000:], length=length)"
      ],
      "metadata": {
        "id": "xCxBvUQPC0vg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Char-RNN"
      ],
      "metadata": {
        "id": "IPuqlREWDtrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"my_shakespeare_model.keras\", monitor=\"val_accuracy\", save_best_only=True)\n",
        "history = model.fit(train_set, validation_data=valid_set, epochs=1,\n",
        "                    callbacks=[model_ckpt])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjlwWoWPDqL7",
        "outputId": "c539f64e-1240-41b8-8b9e-6eb25b25391d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  31244/Unknown \u001b[1m422s\u001b[0m 13ms/step - accuracy: 0.5463 - loss: 1.5017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m31247/31247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 14ms/step - accuracy: 0.5463 - loss: 1.5017 - val_accuracy: 0.5338 - val_loss: 1.6033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shakespeare_model = tf.keras.Sequential([\n",
        "    text_vec_layer,\n",
        "    model,\n",
        "    tf.keras.layers.Lambda(lambda X: X - 2),\n",
        "    model\n",
        "])"
      ],
      "metadata": {
        "id": "wvHM5IBGFOrB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Fake Text"
      ],
      "metadata": {
        "id": "Kk2StpQDJAZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_probas = tf.math.log([[0.5, 0.4, 0.1]])\n",
        "tf.random.set_seed(42)\n",
        "tf.random.categorical(log_probas, num_samples=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK3vg-HjGAAH",
        "outputId": "eedadabb-ef08-4dc3-cf0b-e2d9c483e8b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[0, 0, 1, 1, 1, 0, 0, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def next_char(text, temperature=1):\n",
        "    y_proba = shakespeare_model.predict([text])[0, -1:]\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1)[0, 0]\n",
        "    return text_vec_layer.get_vocabulary()[char_id + 2]"
      ],
      "metadata": {
        "id": "iVUejAmDGmo7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extend_text(text, n_chars=50, temperature=1):\n",
        "    for _ in range(n_chars):\n",
        "        text += next_char(text, temperature)\n",
        "    return text"
      ],
      "metadata": {
        "id": "x3mpiy_uJh4e"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stateful RNN"
      ],
      "metadata": {
        "id": "oFL71ehnKoyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataset_for_stateful_rnn(sequence, length):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(sequence)\n",
        "    ds = ds.window(length + 1, shift=length, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda window: window.batch(length + 1)).batch(1)\n",
        "    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)\n",
        "\n",
        "stateful_train_set = to_dataset_for_stateful_rnn(encoded[:1_000_000], length)\n",
        "stateful_valid_set = to_dataset_for_stateful_rnn(encoded[1_000_000:1_060_000], length)\n",
        "stateful_test_set = to_dataset_for_stateful_rnn(encoded[1_060_000:], length)"
      ],
      "metadata": {
        "id": "9aeYXxtJKsWL"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=n_tokens, output_dim=16),\n",
        "    tf.keras.layers.GRU(128, return_sequences=True, stateful=True),\n",
        "    tf.keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "BHv6RGfsMmnD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResetStatesCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs):\n",
        "        self.model.reset_states()"
      ],
      "metadata": {
        "id": "4eqWijmyNKGF"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}