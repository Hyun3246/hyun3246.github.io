---
title:  "[Hands-On ML] 10장. 케라스를 사용한 인공 신경망 소개 - 2"
excerpt: "keras Sequential API"

categories:
  - Data Science & ML
tags:
  - [머신러닝, 파이썬, 딥러닝, keras]

use_math: true
toc: true
toc_sticky: true

date: 2024-12-03
last_modified_at: 2024-12-03

header:
  overlay_image: https://cdn.jsdelivr.net/gh/Hyun3246/hyun3246.github.io@master/image/overlay image/Hands-on ML.png
---
## Sequential API로 분류 모델 만들기
다음은 fashion MNIST dataset을 이용해서 두 개의 은닉 층으로 이루어진 MLP을 구현한 것이다.

```python
model = tf.keras.Sequential()                           # 1
model.add(tf.keras.layers.Input(shape=[28, 28]))        # 2
model.add(tf.keras.layers.Flatten())                    # 3
model.add(tf.keras.layers.Dense(300, activation='relu'))        # 4
model.add(tf.keras.layers.Dense(100, activation='relu'))
model.add(tf.keras.layers.Dense(10, activation='softmax'))      # 5
```

1. 가장 간단한 keras 신경망 모델인 `Sequential` 모델을 만든다. `Sequential` 모델은 순서대로 연결된 층을 쌓아서 구성된다.
2. 첫 번째 `Input`층이다. 입력의 크기를 알려주어야 keras가 가중치 행렬의 크기를 정할 수 있다.
3. `Flatten` 층으로, 이미지를 1D 배열로 변환한다. 간단한 전처리만 담당하는 층이다.
4. 뉴런 300개를 가진 `Dense`층이다. 활성화 함수는 ReLU를 사용하였다.
5. 출력층으로, 배타적인 클래스이므로 softmax 함수를 사용하였다.

층을 하나씩 추가하는 대신 리스트로 만들어서 전달할 수도 있다.

`model.summary()`를 이용하면 모델의 층, 출력 크기, 파라미터 수 등을 확인할 수 있다.

층의 모든 파라미터는 `get_weights()`를 사용해 접근할 수 있다.

<br/>

## 분류 모델 컴파일
모델을 만들고 나서는 compile()을 호출하여 다음을 정해주어야 한다.

- 사용할 손실 함수
- 옵티마이저(optimizer)
- 평가 지표

```python
model.compile(
    loss='sparse_categorical_crossentropy', 
    optimizer='sgd', 
    metrics=['accuracy'])
```

각 요소들은 어떤 작업이냐에 따라 다르게 선택해야 한다. 예를 들어, 출력이 하나의 정수(e.g. [4])가 아니고 모든 클래스별로 하나의 요소를 가진 원-핫 인코딩(e.g. [0, 0, 0, 1, 0])이라면 `categorical_crossentropy`를 사용해야 한다. 비슷하게 이진 분류나 다중 레이블 분류라면 `binary_crossentropy`를 사용한다.

<br/>

## 모델 훈련과 평가
모델 훈련은 `fit()` 매서드를 호출하면 된다.

```python
history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))
```

위 코드와 같이 `validation_data`를 지정하면 일부를 dev set으로 사용하여 평가를 진행하게 된다.

keras는 친절하게도 진행 표시줄을 통해 훈련 상황과 손실 정보를 제공한다.

> 클래스별로 등장 빈도가 다르다면 `class_weigt` 매개변수를, 샘플별로 가중치를 부여하고 싶다면 `sample_weight` 매개변수를 지정하자.

위의 `history` 객체에는 훈련 파라미터(`history.params`), 에포크 리스트(`history.epoch`)가 포함된다. <span style="color:#F5F5F7">`history.history`에는 에포크가 끝날 때마다 측정된 train set과 dev set의 손실 정보를 담은 딕셔너리가 들어있으며, 다음과 같이 시각화할 수 있다</span>.

```python
import matplotlib.pyplot as plt
import pandas as pd

pd.DataFrame(history.history).plot(
    figsize=(8, 5), xlim=[0, 29], ylim=[0, 1], grid=True, xlabel='Epochs',
    style=['r--', 'r--', 'b-', 'b-*']
)
plt.show()
```
<br/>
<figure style="display:block; text-align:center;">
  <img src="https://cdn.jsdelivr.net/gh/Hyun3246/hyun3246.github.io@master/image/Hands-On ML/keras history graph.png"
       style="width: 40%; height: auto; margin:10px; background: #ffffff">
</figure>
<br/>

test모델로 평가를 진행하려면 `evaluate()` 매서드를 사용하면 된다.

```python
model.evaluate(X_test, y_test)
```

<span style="color:#F5F5F7">하이퍼파라미터 튜닝은 반드시 dev set의 결과로 마무리하고, test set의 결과를 보고 튜닝하는 일은 없어야 한다</span>.

<br/>

## 얘측 만들기
예측은 `predict()` 매서드를 이용한다.

```python
>>> X_new = X_test[:3]
>>> y_proba = model.predict(X_new)
>>> y_proba.round(2)
array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.01, 0.  , 0.86],
       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],
       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],
      dtype=float32)
```

위 결과에서 확인할 수 있듯이 `predict_proba()`처럼 각 클래스의 확률을 반환한다. 따라서 `argmax()`를 이용해 가장 높은 확률을 가지는 클래스를 반환할 수 있다.

```python
>>> import numpy as np
>>> y_pred = y_proba.argmax(axis=1)
>>> y_pred
array([9, 2, 1])
>>> np.array(class_names)[y_pred]
array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')
```
<br/>

## Sequential API로 회귀 모델 만들기
회귀 모델은 전반적으로 분류 모델과 비슷한 구조를 가지고 있으나, 몇 가지 차이점이 있다.

- 출력 층에 하나의 뉴런만이 있다. 또한 활성화 함수를 사용하지 않는다.
- 손실 함수는 MSE, 측정 지표는 RMSE이다.
- `Normalization` 층이 있다. 다만, <span style="color:#F5F5F7">`Normalization` 층을 사용하면 `fit()`을 호출하기 전에 `adapt()` 매서드를 먼저 호출하여 훈련 데이터에 적응시켜야</span> 한다.

```python
norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])
model = tf.keras.Sequential([
    norm_layer,
    tf.keras.layers.Dense(50, activation='relu'),
    tf.keras.layers.Dense(50, activation='relu'),
    tf.keras.layers.Dense(50, activation='relu'),
    tf.keras.layers.Dense(1)
])
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
model.compile(loss='mse', optimizer=optimizer, metrics=['RootMeanSquaredError'])
norm_layer.adapt(X_train)
history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))
mse_test, rmse_test = model.evaluate(X_test, y_test)
X_new = X_test[:3]
y_pred = model.predict(X_new)
```

[코드 보러가기](https://github.com/Hyun3246/Code-Warehouse/blob/ad2a7408449d200fbd64877a24a4377dce1c634f/Hands-On%20ML/Chapter_10_NN_with_Keras.ipynb)


<br/>
<br/>

*별도의 출처 표시가 있는 이미지를 제외한 모든 이미지는 강의자료에서 발췌하였음을 밝힙니다.*